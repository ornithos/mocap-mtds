{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORNN (hard EM) with speed-multiplied foot contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Revise\n",
    "using LinearAlgebra, Random\n",
    "using StatsBase, Statistics\n",
    "using Distributions, MultivariateStats   # Categorical, P(P)CA\n",
    "using Quaternions    # For manipulating 3D Geometry\n",
    "using MeshCat        # For web visualisation / animation\n",
    "using PyPlot         # Plotting\n",
    "using AxUtil         # Cayley, skew matrices\n",
    "using Flux, CuArrays # Optimisation\n",
    "using DSP            # convolution / low-pass (MA) filter\n",
    "\n",
    "# small utils libraries\n",
    "using ProgressMeter, Formatting, ArgCheck, Dates\n",
    "using BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_MOCAP_MTDS = \".\" \n",
    "\n",
    "# Data loading and transformation utils\n",
    "include(joinpath(DIR_MOCAP_MTDS, \"io.jl\"))\n",
    "\n",
    "# MeshCat skeleton visualisation tools\n",
    "include(joinpath(DIR_MOCAP_MTDS, \"mocap_viz.jl\"))\n",
    "\n",
    "# Data scaling utils\n",
    "include(joinpath(DIR_MOCAP_MTDS, \"util.jl\"))\n",
    "\n",
    "# Models: LDS\n",
    "include(joinpath(DIR_MOCAP_MTDS, \"models.jl\"))\n",
    "\n",
    "# Table visualisation\n",
    "include(joinpath(DIR_MOCAP_MTDS, \"pretty.jl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "##    CUSTOM WIDELY USED FUNCTIONS\n",
    "function zero_grad!(P) \n",
    "    for x in P\n",
    "        x.grad .= 0\n",
    "    end\n",
    "end\n",
    "\n",
    "const NoGradModels = Union{model.MyLDS_ng, model.ORNN_ng}\n",
    "const _var_cache = IdDict()\n",
    "\n",
    "mse(Δ::AbstractArray, scale=size(Δ, 1)) = mean(x->x^2, Δ)*scale\n",
    "\n",
    "function mse(d::mocaputil.DataIterator, m::NoGradModels)\n",
    "    obj = map(d) do (y, u, new_state)\n",
    "        new_state && (m.h .= zeros(size(m, 1))) \n",
    "        u_ = (m isa model.ORNN_ng && length(m.inpnn)) > 0 ? vcat(u, m.inpnn(u)) : u\n",
    "        mse(m(u_) - y)\n",
    "    end\n",
    "    m.h .= zeros(size(m, 1))\n",
    "    return dot(obj, mocaputil.weights(d, as_pct=true))\n",
    "end\n",
    "\n",
    "\n",
    "mse(Ds::Vector{D}, m::NoGradModels) where {D <: Dict} = mse(mocaputil.DataIterator(Ds, 1000000), m)\n",
    "mse(D::Dict, m::NoGradModels) = mse(m(D[:U]) - D[:Y])\n",
    "mse(V::Tuple, m::NoGradModels) = mse(m(V[2]) - V[1])\n",
    "\n",
    "# Calculate variance\n",
    "function _calc_var!(cache::IdDict, d::mocaputil.DataIterator)\n",
    "    Y = reduce(hcat, [y for (y, u, h) in d])\n",
    "    _var_cache[d] = var(Y, dims=2)\n",
    "end\n",
    "\n",
    "function _calc_var!(cache::IdDict, d::Vector{D}) where {D <: Dict}\n",
    "    Y = reduce(hcat, [dd[:Y] for dd in d])\n",
    "    _var_cache[d] = var(Y, dims=2)\n",
    "end\n",
    "\n",
    "function Statistics.var(d::Union{mocaputil.DataIterator, Vector{D}}) where {D <: Dict}\n",
    "    !haskey(_var_cache, d) && _calc_var!(_var_cache, d)\n",
    "    return _var_cache[d]\n",
    "end\n",
    "Statistics.var(d::Dict) = var(d[:Y], dims=2)\n",
    "\n",
    "# Standardised MSE\n",
    "smse(Δ::AbstractArray, scale=size(Δ, 1)) = mse(Δ, scale) / sum(var(Δ, dims=2))\n",
    "\n",
    "smse(d::mocaputil.DataIterator, m::NoGradModels) = mse(d, m) / sum(var(d))\n",
    "smse(D::Dict, m::NoGradModels) = mse(m(D[:U]) - D[:Y]) / sum(var(D))\n",
    "smse(Ds::Vector{D}, m::NoGradModels) where {D <: Dict} = mse(mocaputil.DataIterator(Ds, 1000000), m) / sum(var(Ds))\n",
    "smse(D::Tuple, m::NoGradModels) = mse(D, m) / sum(var(D[1], dims=2))\n",
    "\n",
    "rsmse(args...) = sqrt(smse(args...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mse(d::mocaputil.DataIterator, m::model.MTLDS_ng, z::AbstractArray)\n",
    "    @argcheck size(z, 2) == length(d)\n",
    "    obj = map(enumerate(d)) do (ii, (y, u, new_state))\n",
    "        new_state && (m.h .= zeros(size(m, 1))) \n",
    "        cmodel = model.make_lds(m, z[:,ii], m.η_h)\n",
    "        mse(cmodel(u) - y)\n",
    "    end\n",
    "    m.h .= zeros(size(m, 1))\n",
    "    return dot(obj, mocaputil.weights(d, as_pct=true))\n",
    "end\n",
    "\n",
    "\n",
    "function mse(d::mocaputil.DataIterator, m::model.ORNN_ng, z::AbstractArray, nn::Chain)\n",
    "    @argcheck size(z, 2) == length(d)\n",
    "    obj = map(enumerate(d)) do (ii, (y, u, new_state))\n",
    "        new_state && (m.h .= zeros(size(m, 1))) \n",
    "        cmodel = model.make_rnn_psi(m, Tracker.data(nn(z[:,ii])), 1f0)\n",
    "        u_ = length(m.inpnn) > 0 ? vcat(u, m.inpnn(u)) : u\n",
    "        mse(cmodel(u_) - y)\n",
    "    end\n",
    "    m.h .= zeros(size(m, 1))\n",
    "    return dot(obj, mocaputil.weights(d, as_pct=true))\n",
    "end\n",
    "\n",
    "smse(d::mocaputil.DataIterator, m::model.MTLDS_ng, z::AbstractArray) = mse(d, m, z) / sum(var(d))\n",
    "smse(d::mocaputil.DataIterator, m::model.ORNN_ng, z::AbstractArray, nn::Chain) = mse(d, m, z, nn) / sum(var(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "function model.make_grad(s::model.ORNN_ng{T,F,C}) where {T,F,C}\n",
    "    f = Flux.param\n",
    "    inpnn = length(s.inpnn) > 0 ? mapleaves(f, s.inpnn) : s.inpnn\n",
    "    model.ORNN_g{T,F,typeof(inpnn)}(f(s.a), f(s.B), f(s.b), f(s.h), f(s.C), f(s.D), f(s.d), s.σ, inpnn)\n",
    "end\n",
    "\n",
    "function model.make_nograd(s::model.ORNN_g{T,F,C}) where {T,F,C}\n",
    "    f = Tracker.data\n",
    "    inpnn = length(s.inpnn) > 0 ? mapleaves(f, s.inpnn) : s.inpnn\n",
    "    model.ORNN_ng{T,F,typeof(inpnn)}(f(s.a), f(s.B), f(s.b), f(s.h), f(s.C), f(s.D), f(s.d), s.σ, inpnn)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Data\n",
    "See `2_Preprocess.ipynb`\n",
    "\n",
    "**Note that in the current harddisk state**,\n",
    "* `edin_Ys_30fps.bson` was created with `include_ftcontact=false, fps=30`,\n",
    "* `edin_Xs_30fps.bson` was created with `include_ftcontact=true, include_ftmid=true, joint_pos=false, fps=fps, speed=false`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task descriptors\n",
    "styles_lkp = BSON.load(\"styles_lkp\")[:styles_lkp];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "Usraw = BSON.load(\"edin_Xs_30fps.bson\")[:Xs];\n",
    "Ysraw = BSON.load(\"edin_Ys_30fps.bson\")[:Ys];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ysraw = [y[2:end,:] for y in Ysraw]\n",
    "Usraw = [hcat(u[2:end,1:end-8], u[1:end-1,end-7:end]) for u in Usraw];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise inputs and outputs\n",
    "standardize_Y = fit(mocaputil.MyStandardScaler, reduce(vcat, Ysraw),  1)\n",
    "standardize_U = fit(mocaputil.MyStandardScaler, reduce(vcat, Usraw),  1)\n",
    "\n",
    "Ys = [mocaputil.scale_transform(standardize_Y, y[2:end, :] ) for y in Ysraw];  # (1-step ahead of u)\n",
    "Us = [mocaputil.scale_transform(standardize_U, u[1:end-1,:]) for u in Usraw];  # (1-step behind y)\n",
    "\n",
    "@assert (let c=cor(Usraw[1][1:end-1, :], Ysraw[1][2:end, :], dims=1); \n",
    "        !isapprox(maximum(abs.(c[.!isnan.(c)])), 1.0); end) \"some input features perfectly correlated\"\n",
    "\n",
    "# to invert: `mocaputil.invert(standardize_Y, y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENSE CHECK\n",
    "# check that no bugs in constructing U, Y (i.e. esp that t's align and can predict U --> Y)\n",
    "let c=cor(reduce(vcat, Us) |>f64, reduce(vcat, Ys) |> f64, dims=1)\n",
    "    imshow(c, aspect=\"auto\")\n",
    "    nonan_c = c[.!isnan.(c)]\n",
    "    title(format(\"max (abs) corrcoeff: {:.8f}\", maximum(abs.(nonan_c))))\n",
    "    flush(stdout)\n",
    "#     display(findmax(reshape(nonan_c, size(c, 1) - 2, size(c,2))))\n",
    "#     printfmtln(\"10th best result {:.5f}\", reverse(sort(nonan_c))[10]) \n",
    "end\n",
    "colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "expmtdata = mocapio.ExperimentData(Ysraw, [Matrix(y') for y in Ys], \n",
    "    [Matrix(u') for u in Us], styles_lkp);\n",
    "# see ?mocapio.get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MT-ORNN (Hard-EM) experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training set for STL and pooled models.\n",
    "style_ix = 1\n",
    "d = d_state = 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPool, validPool, testPool = mocapio.get_data(expmtdata, style_ix, :split, :pooled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct batch iterator\n",
    "batch_size = 64\n",
    "min_size = 50\n",
    "trainIter = mocaputil.DataIterator(trainPool, batch_size, min_size=min_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# style segment lookups\n",
    "style_names = [\"angry\", \"childlike\", \"depressed\", \"neutral\", \"old\", \"proud\", \"sexy\", \"strutting\"];\n",
    "segment_lkp = [length(mocaputil.DataIterator(mocapio.get_data(expmtdata, i, :train, :stl, split=[0.875,0.125]),\n",
    "            batch_size, min_size=50)) for i in 2:8];\n",
    "segment_lkp = [collect(i+1:j) for (i,j) in zip(vcat(0, cumsum(segment_lkp[1:end-1])), cumsum(segment_lkp))];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base model\n",
    "\n",
    "Model 1: Bottom half only: indices 1-3 (root speed: x,z,w), 4 (root height: y), 5-28 (legs, feet: x,y,z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_ixs = 1:28;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base *LDS*\n",
    "train_neutral = mocapio.get_data(expmtdata, 4, :train, :stl, concat=true, simplify=true);\n",
    "train_neutral[:Y] = train_neutral[:Y][model_1_ixs, :]\n",
    "clds_orig = model.init_LDS_spectral(train_neutral[:Y], train_neutral[:U], d_state, t_ahead=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init a:\n",
    "# extract cθ from a spectral LDS fit for ORNN initialisation (see Henaff et al. for block diag init motivation)\n",
    "lds_evs = eigvals(model.Astable(clds_orig));\n",
    "blkvals = vcat([sqrt((1-ct)/(1+ct)) for ct in real(lds_evs[2:2:end])]', \n",
    "                zeros(Float32, floor(Int, d_state/2))')[1:end-1]\n",
    "a = AxUtil.Math.unmake_lt_strict(diagm(-1=>blkvals), d_state)\n",
    "a = vcat(ones(Float32, 10)*atanh(0.5f0), ones(Float32, 10)*atanh(0.75f0), ones(Float32, d_state-20)*atanh(0.9f0), a);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_d_state, d_out, d_in = size(clds_orig)\n",
    "@argcheck d_state == _d_state\n",
    "_U = train_neutral[:U]\n",
    "cN = size(_U, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in₊ = 30\n",
    "d_in_total = d_in + d_in₊\n",
    "inpnn = Chain(Dense(d_in, 50), Dense(50, d_in₊))\n",
    "inpnn_ng = mapleaves(Tracker.data, inpnn)\n",
    "u_s(u, nn) = vcat(u, nn(u))\n",
    "u_s(u) = u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct init RNN\n",
    "rnn = RNN(d_in_total, d_state, tanh)\n",
    "rnn = RNN(d_in, d_state, tanh)\n",
    "rnn.cell.Wh.data .= model.Astable(a, d_state)\n",
    "\n",
    "# initialise emissions\n",
    "x̂ = reduce(hcat, let _rnn=mapleaves(Tracker.data, rnn); [_rnn(u_s(_U[:,i])) for i in 1:cN]; end)\n",
    "CDd = model._tikhonov_mrdivide(train_neutral[:Y], [x̂; _U; ones(1, cN)], 1e-3);\n",
    "C = param(CDd[:, 1:d_state]) |> f32\n",
    "D = param(CDd[:, d_state+1:end-1]) |> f32\n",
    "d_offset = param(CDd[:,end]) |> f32;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise base model\n",
    "ornn_base = model.ORNN_g(param(a), copy(rnn.cell.Wi), copy(rnn.cell.b), copy(rnn.cell.h),\n",
    "                    copy(C), copy(D), copy(d_offset), tanh, Chain()); #inpnn);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Opimisation model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAM(1e-4)\n",
    "pars = model.pars(ornn_base);   # includes inpnn if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ω = ones(Float32, length(model_1_ixs))\n",
    "ω[1:3]*=5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function optimise_lower!(ornn_base, trainIter, opt, η, n_epochs, shuffle_examples, train_ixs, \n",
    "        ω = ones(Float32, length(train_ixs)))\n",
    "    opt.eta = η\n",
    "    nB = length(trainIter)\n",
    "    W = mocaputil.weights(trainIter; as_pct=false) ./ trainIter.batch_size\n",
    "\n",
    "    history = ones(n_epochs*nB) * NaN\n",
    "\n",
    "    for ee in 1:n_epochs\n",
    "        rnn = RNN(size(ornn_base,3), size(ornn_base,1), ornn_base.σ)\n",
    "\n",
    "        if shuffle_examples\n",
    "            mtl_ixs, trainData = mocaputil.indexed_shuffle(trainIter)\n",
    "        else\n",
    "            mtl_ixs, trainData = 1:length(trainIter), trainIter\n",
    "        end\n",
    "        for (ii, (Yb, Ub, h0)) in zip(mtl_ixs, trainData)\n",
    "            h0 && Flux.reset!(rnn)\n",
    "            Tb = size(Yb, 2)      # not constant\n",
    "\n",
    "            model.build_rnn!(rnn, ornn_base)\n",
    "            x̂ = reduce(hcat, [rnn(u_s(Ub[:,i])) for i in 1:Tb])  |> Tracker.collect\n",
    "            ŷ = let m=ornn_base; m.C*x̂ + m.D*Ub .+ m.d; end                 # adapt C, D, d too.\n",
    "            obj = mean(x->x^2, ω .* (Yb[train_ixs,:] - ŷ)) * 8^2 * W[ii]\n",
    "\n",
    "            Tracker.back!(obj)\n",
    "            history[(ee-1)*nB + ii] = obj.data\n",
    "\n",
    "            if ii % 34 == 0\n",
    "                obj = 1e-3*sum(abs, ornn_base.B)\n",
    "                obj += 1e-3*sum(abs, ornn_base.C)\n",
    "                obj += 1e-3*sum(abs, ornn_base.D)\n",
    "                Tracker.back!(obj)\n",
    "\n",
    "                for p in pars\n",
    "                    Tracker.update!(opt, p, Tracker.grad(p))\n",
    "                end\n",
    "            end\n",
    "\n",
    "            rnn.cell.h.data .= 0       # initial state is a param :/. Easier to reset here.\n",
    "            Flux.truncate!(rnn);\n",
    "        end\n",
    "        printfmtln(\"{:02d}: {:.5f}\", ee, sqrt(mean(history[(1:nB) .+ nB*(ee-1)]))); flush(stdout)\n",
    "\n",
    "    end\n",
    "    return history\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = optimise_lower!(ornn_base, trainIter, opt, 1e-3, 200, true, model_1_ixs, ω)\n",
    "history2 = optimise_lower!(ornn_base, trainIter, opt, 5e-4, 200, true, model_1_ixs, ω)\n",
    "history3 = optimise_lower!(ornn_base, trainIter, opt, 2e-4, 200, true, model_1_ixs, ω)\n",
    "history4 = optimise_lower!(ornn_base, trainIter, opt, 1e-4, 200, true, model_1_ixs, ω)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "smse(trainIter_1, model.make_nograd(ornn_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPool_1 = deepcopy(trainPool);\n",
    "for i in 1:length(trainPool)\n",
    "    trainPool_1[i][:Y] = trainPool[i][:Y][model_1_ixs, :]\n",
    "end\n",
    "trainIter_1 = mocaputil.DataIterator(trainPool_1, batch_size, min_size=min_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "validPool_1 = deepcopy(validPool);\n",
    "for i in 1:length(validPool)\n",
    "    validPool_1[i][:Y] = validPool[i][:Y][model_1_ixs, :]\n",
    "end\n",
    "validIter_1 = mocaputil.DataIterator(validPool_1, batch_size, min_size=min_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "error(\"safeguard\")\n",
    "fname = format(\"ornn_lowermodel_{:d}_pool_{:02d}{:02d}_v{:d}.bson\", d_state, \n",
    "    day(today()), month(today()), batch_size)\n",
    "BSON.bson(fname, m1=model.make_nograd(ornn_base));\n",
    "println(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sqrt.(DSP.conv(history, Windows.rect(nB))[nB:end-nB+1]/nB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "validIters = collect(validIter_1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(tanh.(BSON.load(\"ornn_2L_100_3_pool_2006_v64.bson\")[:m1].a[1:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(ornn_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(tanh.(ornn_base.a.data[1:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = subplots(5,4,figsize=(10,10))\n",
    "dset_i = 567\n",
    "for i in 1:20\n",
    "    trainIters = collect(trainIter);\n",
    "    _Yb, _Ub, _h = trainIters[dset_i+i]\n",
    "    _Tb = size(_Yb, 2)\n",
    "    rnn_ng = mapleaves(Tracker.data, RNN(d_in, d_state, ornn_base.σ))\n",
    "    ornn_base_ng = model.make_nograd(ornn_base)\n",
    "    model.build_rnn!(rnn_ng, ornn_base_ng)\n",
    "    x̂ = reduce(hcat, [rnn_ng(_Ub[:,i]) for i in 1:_Tb])\n",
    "    cldsY = let m=ornn_base_ng; m.C*x̂ + m.D*_Ub .+ m.d; end\n",
    "\n",
    "    axs[:][i].plot(_Yb'[:, 1])\n",
    "    axs[:][i].plot(cldsY'[:, 1], alpha=0.4)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_i = 55\n",
    "\n",
    "trainIters = collect(trainIter);\n",
    "_Yb, _Ub, _h = trainIters[dset_i]\n",
    "_Yb, _Ub = hcat(_Yb, trainIters[dset_i+1][1]), hcat(_Ub, trainIters[dset_i+1][2])\n",
    "_Tb = size(_Yb, 2)\n",
    "rnn_ng = mapleaves(Tracker.data, RNN(d_in, d_state, ornn_base.σ))\n",
    "ornn_base_ng = model.make_nograd(ornn_base)\n",
    "model.build_rnn!(rnn_ng, ornn_base_ng)\n",
    "x̂ = reduce(hcat, [rnn_ng(u_s(_Ub[:,i])) for i in 1:_Tb])\n",
    "cldsY = let m=ornn_base_ng; m.C*x̂ + m.D*_Ub .+ m.d; end\n",
    "\n",
    "fig, axs = subplots(7,4,figsize=(10,12))\n",
    "offset = 0\n",
    "for i = 1:28\n",
    "    axs[:][i].plot(_Yb'[:, i+offset])\n",
    "    axs[:][i].plot(cldsY'[:, i+offset], alpha=0.4)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIters = collect(trainIter);\n",
    "function get_lower_prediction(ornn_base, _Ub, _h)\n",
    "    d_state, d_out, d_in = size(ornn_base)\n",
    "    _Tb = size(_Ub, 2)\n",
    "    rnn_ng = mapleaves(Tracker.data, RNN(d_in, d_state, ornn_base.σ))\n",
    "    _h && Flux.reset!(rnn_ng)\n",
    "    ornn_base_ng = model.make_nograd(ornn_base)\n",
    "    model.build_rnn!(rnn_ng, ornn_base_ng)\n",
    "    x̂ = reduce(hcat, [rnn_ng(_Ub[:,i]) for i in 1:_Tb])\n",
    "    let m=ornn_base_ng; m.C*x̂ + m.D*_Ub .+ m.d; end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPool2 = deepcopy(trainPool);\n",
    "for i in 1:length(trainPool)\n",
    "    trainPool2[i][:U] = get_lower_prediction(ornn_base, trainPool[i][:U], true)\n",
    "end\n",
    "trainIter2 = mocaputil.DataIterator(trainPool2, batch_size, min_size=min_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ornn_base_lower = copy(ornn_base);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MT-ORNN\n",
    "Note that the MTORNN object is still not mature, and I'm just manipulating directly below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ornn_optim = copy(ornn_base);   # copy to avoid over-writing initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ornn_optim.C = Tracker.param(Flux.glorot_normal(64, size(ornn_optim,1)));\n",
    "ornn_optim.B = Tracker.param(Flux.glorot_normal(size(ornn_optim, 1),28));\n",
    "ornn_optim.D = Tracker.param(Flux.glorot_normal(size(ornn_optim, 2),28));\n",
    "ornn_optim.D[model_1_ixs, model_1_ixs] = AxUtil.Arr.eye(length(model_1_ixs))\n",
    "ornn_optim.d = Tracker.param(zeros(Float32, size(ornn_optim, 2)));\n",
    "ornn_optim_ng = model.make_nograd(ornn_optim);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-task manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3                 # dimension of manifold\n",
    "d_nn = 200            # \"complexity\" of manifold\n",
    "d_subspace = 30;      # dim of subspace (⊆ parameter space) containg the manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_par = [length(x) for x in model.pars_no_inpnn(ornn_optim)] |> sum\n",
    "nn = Chain(Dense(k, d_nn, tanh), Dense(d_nn, d_subspace, identity), \n",
    "    Dense(d_subspace, d_par, identity, initW = ((dims...)->Flux.glorot_uniform(dims...)*0.05f0)))\n",
    "nn_ng = mapleaves(Tracker.data, nn)\n",
    "Zmap = Flux.param(randn(Float32, k, length(trainIter))*0.01f0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAM(1e-4)\n",
    "pars = Flux.params(nn, Zmap);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "function optimise_upper!(ornn_optim, Zmap, trainIter, opt, η, n_epochs, shuffle_examples, lower_ixs)\n",
    "    opt.eta = η\n",
    "    nB = length(trainIter)\n",
    "    W = mocaputil.weights(trainIter; as_pct=false) ./ batch_size\n",
    "    history = ones(n_epochs*nB) * NaN\n",
    "\n",
    "    for ee in 1:n_epochs\n",
    "        rnn = RNN(size(ornn_optim,3), size(ornn_optim,1), ornn_optim.σ)\n",
    "\n",
    "        if shuffle_examples\n",
    "            mtl_ixs, trainData = mocaputil.indexed_shuffle(trainIter)\n",
    "        else\n",
    "            mtl_ixs, trainData = 1:length(trainIter), trainIter\n",
    "        end\n",
    "        for (ii, (Yb, Ub, h0)) in zip(mtl_ixs, trainData)\n",
    "            h0 && Flux.reset!(rnn)\n",
    "            Tb = size(Yb, 2)      # not constant\n",
    "            Zs_post = Zmap[:,ii]  #.+ convert(Array{Float32}, AxUtil.Random.sobol_gaussian(m_bprop,2)'*0.01)\n",
    "\n",
    "            c_ornn = model.make_rnn_psi(ornn_optim, nn(Zs_post), 1f0)\n",
    "\n",
    "            model.build_rnn!(rnn, c_ornn)\n",
    "            x̂ = reduce(hcat, [rnn(Ub[:,i]) for i in 1:Tb])  |> Tracker.collect\n",
    "            #         ŷ = let m=ornn_optim; m.C*x̂ + m.D*Ub .+ m.d; end   # keep same C, D, d ∀ tasks\n",
    "            DU = vcat(Ub, c_ornn.D[lower_ixs[end]+1:end,:]*Ub)       # strictly residual connection to lower\n",
    "            ŷ = let m=c_ornn; m.C*x̂ + DU .+ m.d; end                 # adapt C, D, d too.\n",
    "            obj = mean(x->x^2, Yb - ŷ) * 8^2 * W[ii]\n",
    "\n",
    "            # Prior penalty\n",
    "            obj += 0.5*sum(Zs_post .* Zs_post)\n",
    "\n",
    "            Tracker.back!(obj)\n",
    "            history[(ee-1)*nB + ii] = obj.data\n",
    "\n",
    "            if ii % 34 == 0\n",
    "                for layer in nn.layers\n",
    "                    obj += 1e-3*sum(abs, layer.W)\n",
    "                    obj += 1e-3*sum(abs, layer.b)\n",
    "                end\n",
    "\n",
    "                for p in pars\n",
    "                    Tracker.update!(opt, p, Tracker.grad(p))\n",
    "                end\n",
    "            end\n",
    "\n",
    "            rnn.cell.h.data .= 0       # initial state is a param :/. Easier to reset here.\n",
    "            Flux.truncate!(rnn);\n",
    "        end\n",
    "        printfmtln(\"{:02d}: {:.5f}\", ee, sqrt(mean(history[(1:nB) .+ nB*(ee-1)]))); flush(stdout)\n",
    "\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = optimise_upper!(ornn_optim, Zmap, trainIter2, opt, 1e-3, 200, true, model_1_ixs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global optimisation of latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsmp = 300\n",
    "_Zsmp = cholesky(cov(Zmap.data')).U * f32(AxUtil.Random.sobol_gaussian(nsmp, k)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate error matrix with above samples\n",
    "res = ones(Float32, length(trainIter), nsmp)\n",
    "\n",
    "ornn_optim_ng = model.make_nograd(ornn_optim);\n",
    "rnn_ng = mapleaves(Tracker.data, RNN(d_in, d_state, ornn_optim.σ))\n",
    "@time for i in 1:nsmp\n",
    "    _ψ = nn_ng(_Zsmp[:,i]);\n",
    "    c_ornn = model.make_rnn_psi(ornn_optim_ng, _ψ, 1f0)\n",
    "    model.build_rnn!(rnn_ng, c_ornn)\n",
    "    for (n, (Yb, Ub, h0)) in enumerate(trainIter2)\n",
    "        h0 && Flux.reset!(rnn_ng)\n",
    "        Tb = size(Yb, 2)\n",
    "        x̂ = reduce(hcat, [rnn_ng(Ub[:,i]) for i in 1:Tb])\n",
    "        ŷ = let m=c_ornn; m.C*x̂ + m.D*Ub .+ m.d; end\n",
    "        res[n,i] = mean(x->x^2, Yb - ŷ)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from implicit posterior (SNIS)\n",
    "pz = softmax(-32*(res')) \n",
    "z_smpopt = copy(Zmap.data)\n",
    "for i in 1:length(trainIter2)\n",
    "    z_smpopt[:,i] = _Zsmp[:, argmax(pz[:,i])]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to compare with current position\n",
    "ax = gca()\n",
    "# ax.scatter(_Zsmp[:,1], _Zsmp[:,2], alpha=0.1)\n",
    "for i in 1:7\n",
    "    ixs = segment_lkp[i]\n",
    "    z = z_smpopt[:, ixs] .+ randn(Float32, k, length(ixs))*0.005\n",
    "    ax.scatter(z[1,:], z[2,:], color=ColorMap(\"tab10\")(i-1), alpha=0.5)\n",
    "end\n",
    "legend(style_names[(1:7) .+ 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update latents\n",
    "# error(\"safeguard\")\n",
    "Zmap.data .= z_smpopt .+ randn(Float32, 2, length(trainIter))*0.005;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Continue optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = optimise_upper!(ornn_optim, Zmap, trainIter2, opt, 5e-4, 150, true, model_1_ixs)\n",
    "history3 = optimise_upper!(ornn_optim, Zmap, trainIter2, opt, 2e-4, 150, true, model_1_ixs)\n",
    "history4 = optimise_upper!(ornn_optim, Zmap, trainIter2, opt, 1e-4, 150, true, model_1_ixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "smse(trainIter2, model.make_nograd(ornn_optim), Zmap.data, nn_ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error(\"safeguard\")\n",
    "fname = format(\"ornn_2L_{:d}_{:d}_pool_{:02d}{:02d}_v{:d}.bson\", d_state, \n",
    "    k, day(today()), month(today()), batch_size)\n",
    "BSON.bson(fname, m1=model.make_nograd(ornn_base), m2=ornn_optim_ng, nn=nn_ng, Zmap=Zmap.data);\n",
    "println(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ornn_base, ornn_optim_ng, nn_ng, Zmap = let b=BSON.load(\"ornn_2L_100_2_pool_1806_v64.bson\"); \n",
    "#     b[:m1], b[:m2], b[:nn], b[:Zmap]; end\n",
    "# ornn_base = model.make_grad(ornn_base)\n",
    "# ornn_optim = model.make_grad(ornn_optim_ng)\n",
    "# ornn_optim_ng = model.make_nograd(ornn_optim)\n",
    "# Zmap = Flux.param(Zmap);\n",
    "# nn = mapleaves(Tracker.param, nn_ng)\n",
    "# nn_ng = mapleaves(Tracker.data, nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot optimisation progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sqrt.(DSP.conv(history, Windows.rect(nB))[nB:end-nB+1]/nB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "std(Zmap.data, dims=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gca()\n",
    "for i in 1:7\n",
    "    ixs = segment_lkp[i]\n",
    "    ixs = ixs[(520 .< ixs .< 530) .| (35 .< ixs .< 45)]\n",
    "    z = Zmap.data[:, ixs] / 0.082 \n",
    "    ax.scatter(z[1,:], z[2,:], color=ColorMap(\"tab10\")(i-1), alpha=0.5)\n",
    "end\n",
    "legend(style_names[(1:7) .+ 1])\n",
    "\n",
    "# savefig(\"2D_viz.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise fit (and MT variability) for a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_i = 30\n",
    "n_draws = 3\n",
    "\n",
    "trainIters = collect(trainIter);\n",
    "_Yb, _Ub, _h = trainIters[dset_i]\n",
    "_Tb = size(_Yb, 2)\n",
    "_eps = cholesky(cov(Zmap.data')).U * randn(Float32, 2, n_draws)\n",
    "_eps = Zmap.data[:, rand(Categorical(ones(length(trainIter))/length(trainIter)), n_draws)]\n",
    "_eps[:,1] = Zmap.data[:,dset_i]\n",
    "cldsY = map(1:n_draws) do i\n",
    "    _ψ = nn_ng(_eps[:,i]);    \n",
    "    c_ornn = model.make_rnn_psi(ornn_optim_ng, _ψ, 1f0)\n",
    "    model.build_rnn!(rnn_ng, c_ornn)\n",
    "    x̂ = reduce(hcat, [rnn_ng(_Ub[:,i]) for i in 1:_Tb])\n",
    "    let m=c_ornn; m.C*x̂ + m.D*_Ub .+ m.d; end\n",
    "end\n",
    "\n",
    "fig, axs = subplots(5,4,figsize=(10,10))\n",
    "offset = 40\n",
    "for i = 1:20\n",
    "    axs[:][i].plot(_Yb'[:, i+offset])\n",
    "    for j in 1:n_draws\n",
    "        axs[:][i].plot(cldsY[j]'[:, i+offset], alpha=0.4)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
