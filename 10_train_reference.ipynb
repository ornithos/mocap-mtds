{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Reference Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Revise\n",
    "using LinearAlgebra, Random\n",
    "using StatsBase, Statistics\n",
    "using Distributions, MultivariateStats   # Categorical, P(P)CA\n",
    "using Quaternions    # For manipulating 3D Geometry\n",
    "using MeshCat        # For web visualisation / animation\n",
    "using PyPlot         # Plotting\n",
    "using AxUtil         # Cayley, skew matrices\n",
    "using Flux, CuArrays # Optimisation\n",
    "using DSP            # convolution / low-pass (MA) filter\n",
    "\n",
    "# small utils libraries\n",
    "using ProgressMeter, Formatting, ArgCheck, Dates\n",
    "using BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_MOCAP_MTDS = \".\" \n",
    "\n",
    "# Data loading and transformation utils\n",
    "include(joinpath(DIR_MOCAP_MTDS, \"io.jl\"))\n",
    "\n",
    "# MeshCat skeleton visualisation tools\n",
    "include(joinpath(DIR_MOCAP_MTDS, \"mocap_viz.jl\"))\n",
    "\n",
    "# Data scaling utils\n",
    "include(joinpath(DIR_MOCAP_MTDS, \"util.jl\"))\n",
    "\n",
    "# Models: LDS\n",
    "include(joinpath(DIR_MOCAP_MTDS, \"models.jl\"))\n",
    "\n",
    "# Table visualisation\n",
    "include(joinpath(DIR_MOCAP_MTDS, \"pretty.jl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "##    CUSTOM WIDELY USED FUNCTIONS\n",
    "function zero_grad!(P) \n",
    "    for x in P\n",
    "        x.grad .= 0\n",
    "    end\n",
    "end\n",
    "\n",
    "const NoGradModels = Union{model.MyLDS_ng, model.ORNN_ng}\n",
    "const _var_cache = IdDict()\n",
    "\n",
    "mse(Δ::AbstractArray, scale=size(Δ, 1)) = mean(x->x^2, Δ)*scale\n",
    "\n",
    "function mse(d::mocaputil.DataIterator, m::NoGradModels)\n",
    "    obj = map(d) do (y, u, new_state)\n",
    "        new_state && (m.h .= zeros(size(m, 1))) \n",
    "        mse(m(u) - y)\n",
    "    end\n",
    "    m.h .= zeros(size(m, 1))\n",
    "    return dot(obj, mocaputil.weights(d, as_pct=true))\n",
    "end\n",
    "\n",
    "\n",
    "mse(Ds::Vector{D}, m::NoGradModels) where {D <: Dict} = mse(mocaputil.DataIterator(Ds, 1000000), m)\n",
    "mse(D::Dict, m::NoGradModels) = mse(m(D[:U]) - D[:Y])\n",
    "mse(V::Tuple, m::NoGradModels) = mse(m(V[2]) - V[1])\n",
    "\n",
    "# Calculate variance\n",
    "function _calc_var!(cache::IdDict, d::mocaputil.DataIterator)\n",
    "    Y = reduce(hcat, [y for (y, u, h) in d])\n",
    "    _var_cache[d] = var(Y, dims=2)\n",
    "end\n",
    "\n",
    "function _calc_var!(cache::IdDict, d::Vector{D}) where {D <: Dict}\n",
    "    Y = reduce(hcat, [dd[:Y] for dd in d])\n",
    "    _var_cache[d] = var(Y, dims=2)\n",
    "end\n",
    "\n",
    "function Statistics.var(d::Union{mocaputil.DataIterator, Vector{D}}) where {D <: Dict}\n",
    "    !haskey(_var_cache, d) && _calc_var!(_var_cache, d)\n",
    "    return _var_cache[d]\n",
    "end\n",
    "Statistics.var(d::Dict) = var(d[:Y], dims=2)\n",
    "\n",
    "# Standardised MSE\n",
    "smse(Δ::AbstractArray, scale=size(Δ, 1)) = mse(Δ, scale) / sum(var(Δ, dims=2))\n",
    "\n",
    "smse(d::mocaputil.DataIterator, m::NoGradModels) = mse(d, m) / sum(var(d))\n",
    "smse(D::Dict, m::NoGradModels) = mse(m(D[:U]) - D[:Y]) / sum(var(D))\n",
    "smse(Ds::Vector{D}, m::NoGradModels) where {D <: Dict} = mse(mocaputil.DataIterator(Ds, 1000000), m) / sum(var(Ds))\n",
    "smse(D::Tuple, m::NoGradModels) = mse(D, m) / sum(var(D[1], dims=2))\n",
    "\n",
    "rsmse(args...) = sqrt(smse(args...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mse(d::mocaputil.DataIterator, m::model.MTLDS_ng, z::AbstractArray)\n",
    "    @argcheck size(z, 2) == length(d)\n",
    "    obj = map(enumerate(d)) do (ii, (y, u, new_state))\n",
    "        new_state && (m.h .= zeros(size(m, 1))) \n",
    "        cmodel = model.make_lds(m, z[:,ii], m.η_h)\n",
    "        mse(cmodel(u) - y)\n",
    "    end\n",
    "    m.h .= zeros(size(m, 1))\n",
    "    return dot(obj, mocaputil.weights(d, as_pct=true))\n",
    "end\n",
    "\n",
    "\n",
    "function mse(d::mocaputil.DataIterator, m::model.ORNN_ng, z::AbstractArray, nn::Chain)\n",
    "    @argcheck size(z, 2) == length(d)\n",
    "    obj = map(enumerate(d)) do (ii, (y, u, new_state))\n",
    "        new_state && (m.h .= zeros(size(m, 1))) \n",
    "        cmodel = model.make_rnn_psi(m, Tracker.data(nn(z[:,ii])), 1f0)\n",
    "        mse(cmodel(u) - y)\n",
    "    end\n",
    "    m.h .= zeros(size(m, 1))\n",
    "    return dot(obj, mocaputil.weights(d, as_pct=true))\n",
    "end\n",
    "\n",
    "smse(d::mocaputil.DataIterator, m::model.MTLDS_ng, z::AbstractArray) = mse(d, m, z) / sum(var(d))\n",
    "smse(d::mocaputil.DataIterator, m::model.ORNN_ng, z::AbstractArray, nn::Chain) = mse(d, m, z, nn) / sum(var(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Data\n",
    "See `2_Preprocess.ipynb`\n",
    "\n",
    "**Note that in the current harddisk state**,\n",
    "* `edin_Ys_30fps.bson` was created with `include_ftcontact=false, fps=30`,\n",
    "* `edin_Xs_30fps.bson` was created with `include_ftcontact=true, include_ftmid=true, joint_pos=false, fps=fps, speed=false`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task descriptors\n",
    "styles_lkp = BSON.load(\"styles_lkp\")[:styles_lkp];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "Usraw = BSON.load(\"edin_Xs_30fps.bson\")[:Xs];\n",
    "Ysraw = BSON.load(\"edin_Ys_30fps.bson\")[:Ys];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise inputs and outputs\n",
    "standardize_Y = fit(mocaputil.MyStandardScaler, reduce(vcat, Ysraw),  1)\n",
    "standardize_U = fit(mocaputil.MyStandardScaler, reduce(vcat, Usraw),  1)\n",
    "\n",
    "Ys = [mocaputil.scale_transform(standardize_Y, y[2:end, :] ) for y in Ysraw];  # (1-step ahead of u)\n",
    "Us = [mocaputil.scale_transform(standardize_U, u[1:end-1,:]) for u in Usraw];  # (1-step behind y)\n",
    "\n",
    "@assert (let c=cor(Usraw[1][1:end-1, :], Ysraw[1][2:end, :], dims=1); \n",
    "        !isapprox(maximum(abs.(c[.!isnan.(c)])), 1.0); end) \"some input features perfectly correlated\"\n",
    "\n",
    "# to invert: `mocaputil.invert(standardize_Y, y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENSE CHECK\n",
    "# check that no bugs in constructing U, Y (i.e. esp that t's align and can predict U --> Y)\n",
    "let c=cor(reduce(vcat, Us) |>f64, reduce(vcat, Ys) |> f64, dims=1)\n",
    "    imshow(c, aspect=\"auto\")\n",
    "    nonan_c = c[.!isnan.(c)]\n",
    "    title(format(\"max (abs) corrcoeff: {:.8f}\", maximum(abs.(nonan_c))))\n",
    "    flush(stdout)\n",
    "    display(findmax(reshape(nonan_c, size(c, 1) - 2, size(c,2))))\n",
    "    printfmtln(\"10th best result {:.5f}\", reverse(sort(nonan_c))[10]) \n",
    "end\n",
    "colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expmtdata = mocapio.ExperimentData(Ysraw, [Matrix(y') for y in Ys], \n",
    "    [Matrix(u') for u in Us], styles_lkp);\n",
    "# see ?mocapio.get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MT-LDS (Hard-EM) experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training set for STL and pooled models.\n",
    "style_ix = 1\n",
    "d = 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPool, validPool, testPool = mocapio.get_data(expmtdata, style_ix, :split, :pooled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct batch iterator\n",
    "batch_size = 64\n",
    "min_size = 50\n",
    "trainIter = mocaputil.DataIterator(trainPool, batch_size, min_size=min_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# style segment lookups\n",
    "style_names = [\"angry\", \"childlike\", \"depressed\", \"neutral\", \"old\", \"proud\", \"sexy\", \"strutting\"];\n",
    "segment_lkp = [length(mocaputil.DataIterator(mocapio.get_data(expmtdata, i, :train, :stl, split=[0.875,0.125]),\n",
    "            batch_size, min_size=50)) for i in 1:7];\n",
    "segment_lkp = [collect(i+1:j) for (i,j) in zip(vcat(0, cumsum(segment_lkp[1:end-1])), cumsum(segment_lkp))];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model\n",
    "clds_orig = model.init_LDS_spectral(trainPool[1][:Y][:,1:200], trainPool[1][:U][:,1:200], d)  # whatever...\n",
    "clds_g = model.make_grad(clds_orig)\n",
    "clds   = model.make_nograd(clds_g);   # MUST DO THIS SECOND, (Flux.param takes copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-task manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2                 # dimension of manifold\n",
    "d_nn = 200            # \"complexity\" of manifold\n",
    "d_subspace = 20       # dim of subspace (⊆ parameter space) containg the manifold\n",
    "d_out = size(clds,2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_par = [length(x) for x in model.get_pars(clds)] |> sum\n",
    "nn = Chain(Dense(k, d_nn, tanh), Dense(d_nn, d_subspace, identity), \n",
    "    Dense(d_subspace, d_par,identity, initW = ((dims...)->Flux.glorot_uniform(dims...)*0.5f0)))\n",
    "nn_ng = mapleaves(Tracker.data, nn)\n",
    "Zmap = Flux.param(randn(Float32, k, length(trainIter))*0.01f0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MT-LDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero!(clds)\n",
    "clogσ = repeat([0f0], size(clds, 2))\n",
    "cmtlds_g = model.mtldsg_from_lds(clds, nn, clogσ, 0.1f0);\n",
    "cmtlds = model.make_nograd(cmtlds_g);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAM(1e-4)\n",
    "pars = Flux.params(nn, Zmap);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "opt.eta = 1e-3  # ... 8e-5\n",
    "shuffle_examples = true\n",
    "\n",
    "nB = length(trainIter)\n",
    "W = mocaputil.weights(trainIter; as_pct=false) ./ batch_size #|> gpu\n",
    "\n",
    "history = ones(n_epochs*nB) * NaN\n",
    "\n",
    "for ee in 1:n_epochs\n",
    "    if shuffle_examples\n",
    "        mtl_ixs, trainData = mocaputil.indexed_shuffle(trainIter)\n",
    "    else\n",
    "        mtl_ixs, trainData = 1:length(trainIter), trainIter\n",
    "    end\n",
    "    for (ii, (Yb, Ub, h0)) in zip(mtl_ixs, trainData)\n",
    "        h0 && model.zero_state!(cmtlds)\n",
    "        Tb = size(Yb, 2)      # not constant\n",
    "        \n",
    "        ψ = cmtlds_g.nn(Zmap[:,ii])\n",
    "        lds = model._make_lds_psi(cmtlds_g, ψ, cmtlds_g.η_h)\n",
    "        X   = model.state_rollout(lds, Ub)\n",
    "        Ŷ   = lds.C * X + lds.D * Ub .+ lds.d;\n",
    "        cmtlds.h = Tracker.data(X)[:,end]   # truncated backprop\n",
    "        \n",
    "        obj = mean(x->x^2, Yb - Ŷ) * 8^2 * W[ii]\n",
    "\n",
    "        # Prior penalty (weak - avoid collapse --> 0, ∵ Hard-EM indeterminacy)\n",
    "        obj += 0.02*sum(Zmap[:,ii] .* Zmap[:,ii])\n",
    "        \n",
    "        Tracker.back!(obj)\n",
    "        history[(ee-1)*nB + ii] = obj.data\n",
    "        \n",
    "        if ii % 34 == 0\n",
    "            # regularisation\n",
    "            for layer in nn.layers\n",
    "                obj += 1e-3*sum(abs, layer.W)\n",
    "                obj += 1e-3*sum(abs, layer.b)\n",
    "            end\n",
    "            \n",
    "            for p in pars\n",
    "                Tracker.update!(opt, p, Tracker.grad(p))\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    (ee % 1 == 0) && println(sqrt(mean(history[(1:nB) .+ nB*(ee-1)]))); flush(stdout)\n",
    "\n",
    "end "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot optimisation progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sqrt.(DSP.conv(history, Windows.rect(nB))[nB:end-nB+1]/nB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gca()\n",
    "for i in 1:7\n",
    "    ixs = segment_lkp[i]\n",
    "    z = Zmap.data[:, ixs]\n",
    "    ax.scatter(z[1,:], z[2,:], color=ColorMap(\"tab10\")(i-1), alpha=0.5)\n",
    "end\n",
    "legend(style_names[(1:7) .+ 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error(\"safeguard\")\n",
    "BSON.bson(format(\"cmtlds{:d}_pool_{:d}{:02d}_v{:d}.bson\", \n",
    "        d, day(today()), month(today()), batch_size), m=cmtlds, Zmap=Zmap.data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global optimisation of latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsmp = 600\n",
    "cholesky(cov(Zmap.data')).U * f32(AxUtil.Random.sobol_gaussian(nsmp, 2)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate error matrix with above samples\n",
    "res = ones(Float32, length(trainIter), 600)\n",
    "for i in 1:nsmp\n",
    "    lds = model.make_lds(cmtlds, _Zsmp[:,i], cmtlds.η_h)\n",
    "    for (n, (Yb, Ub, h0)) in enumerate(trainIter)\n",
    "        h0 && model.zero_state!(lds)\n",
    "        ŷ = lds(Ub)\n",
    "        res[n,i] = mean(x->x^2, Yb - ŷ)\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find MAP of from implicit posterior \n",
    "pz = softmax(-32*(Matrix(res')))   # note that this is much less peaked than it should be=> mean not sum.\n",
    "z_smpopt = copy(Zmap.data)\n",
    "for i in 1:length(trainIter)\n",
    "    z_smpopt[:,i] = _Zsmp[:, argmax(pz[:,i])]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to compare with current position\n",
    "ax = gca()\n",
    "# ax.scatter(_Zsmp[:,1], _Zsmp[:,2], alpha=0.1)\n",
    "for i in 1:7\n",
    "    ixs = segment_lkp[i]\n",
    "    z = z_smpopt[:, ixs] .+ randn(Float32, 2, length(ixs))*0.005\n",
    "    ax.scatter(z[1,:], z[2,:], color=ColorMap(\"tab10\")(i-1), alpha=0.5)\n",
    "end\n",
    "legend(style_names[(1:7) .+ 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update latents\n",
    "error(\"safeguard\")\n",
    "Zmap.data .= z_smpopt .+ randn(Float32, 2, length(trainIter))*0.005;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise fit (and MT variability) for a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_i = 100\n",
    "n_draws = 3\n",
    "\n",
    "trainIters = collect(trainIter);\n",
    "_Yb, _Ub, _h = trainIters[dset_i]\n",
    "_eps = cholesky(cov(Zmap.data')).U * randn(Float32, 2, n_draws)\n",
    "_eps = Zmap.data[:, rand(Categorical(ones(length(trainIter))/length(trainIter)), n_draws)]\n",
    "_eps[:,1] = Zmap.data[:,dset_i]\n",
    "cldsY = map(1:n_draws) do i\n",
    "    ψ = cmtlds.nn(_eps[:,i])\n",
    "    lds = model._make_lds_psi(cmtlds, ψ, cmtlds.η_h)\n",
    "    lds(_Ub)\n",
    "end\n",
    "\n",
    "fig, axs = subplots(5,4,figsize=(10,10))\n",
    "offset = 0\n",
    "for i = 1:20\n",
    "    axs[:][i].plot(_Yb'[:, i+offset])\n",
    "    for j in 1:n_draws\n",
    "        axs[:][i].plot(cldsY[j]'[:, i+offset], alpha=0.4)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MT-ORNN (Hard-EM) experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training set for STL and pooled models.\n",
    "style_ix = 1\n",
    "d = d_state = 100;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPool, validPool, testPool = mocapio.get_data(expmtdata, style_ix, :split, :pooled);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct batch iterator\n",
    "batch_size = 64\n",
    "min_size = 50\n",
    "trainIter = mocaputil.DataIterator(trainPool, batch_size, min_size=min_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# style segment lookups\n",
    "style_names = [\"angry\", \"childlike\", \"depressed\", \"neutral\", \"old\", \"proud\", \"sexy\", \"strutting\"];\n",
    "segment_lkp = [length(mocaputil.DataIterator(mocapio.get_data(expmtdata, i, :train, :stl, split=[0.875,0.125]),\n",
    "            batch_size, min_size=50)) for i in 1:7];\n",
    "segment_lkp = [collect(i+1:j) for (i,j) in zip(vcat(0, cumsum(segment_lkp[1:end-1])), cumsum(segment_lkp))];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base *LDS*\n",
    "train_neutral = mocapio.get_data(expmtdata, 4, :train, :stl, concat=true, simplify=true);\n",
    "clds_orig = model.init_LDS_spectral(train_neutral[:Y], train_neutral[:U], d_state, t_ahead=ceil(Int, d_state/64));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init a:\n",
    "# extract cθ from a spectral LDS fit for ORNN initialisation (see Henaff et al. for block diag init motivation)\n",
    "lds_evs = eigvals(model.Astable(clds_orig));\n",
    "blkvals = vcat([sqrt((1-ct)/(1+ct)) for ct in real(lds_evs[2:2:end])]', \n",
    "                zeros(Float32, floor(Int, d_state/2))')[1:end-1]\n",
    "a = AxUtil.Math.unmake_lt_strict(diagm(-1=>blkvals), d_state)\n",
    "a = vcat(ones(Float32, d_state)*atanh(0.9f0), a);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_d_state, d_out, d_in = size(clds_orig)\n",
    "@argcheck d_state == _d_state\n",
    "_U = train_neutral[:U]\n",
    "cN = size(_U, 2)\n",
    "\n",
    "# construct init RNN\n",
    "rnn = RNN(d_in, d_state, tanh)\n",
    "rnn.cell.Wh.data .= model.Astable(a, d_state)\n",
    "\n",
    "# initialise emissions\n",
    "x̂ = reduce(hcat, let _rnn=mapleaves(Tracker.data, rnn); [_rnn(_U[:,i]) for i in 1:cN]; end)\n",
    "CDd = model._tikhonov_mrdivide(train_neutral[:Y], [x̂; _U; ones(1, cN)], 1e-3);\n",
    "C = param(CDd[:, 1:d_state]) |> f32\n",
    "D = param(CDd[:, d_state+1:end-1]) |> f32\n",
    "d_offset = param(CDd[:,end]) |> f32;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise base model\n",
    "ornn_base = model.ORNN_g(param(a), copy(rnn.cell.Wi), copy(rnn.cell.b), copy(rnn.cell.h),\n",
    "                    copy(C), copy(D), copy(d_offset), tanh, Chain());  # empty input NN (Chain())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-task manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2                 # dimension of manifold\n",
    "d_nn = 200            # \"complexity\" of manifold\n",
    "d_subspace = 30;       # dim of subspace (⊆ parameter space) containg the manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_par = [length(x) for x in model.pars_no_inpnn(ornn_base)] |> sum\n",
    "nn = Chain(Dense(k, d_nn, tanh), Dense(d_nn, d_subspace, identity), \n",
    "    Dense(d_subspace, d_par, identity, initW = ((dims...)->Flux.glorot_uniform(dims...)*0.05f0)))\n",
    "nn_ng = mapleaves(Tracker.data, nn)\n",
    "Zmap = Flux.param(randn(Float32, k, length(trainIter))*0.01f0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MT-ORNN\n",
    "Note that the MTORNN object is still not mature, and I'm just manipulating directly below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ornn_optim = copy(ornn_base);   # copy to avoid over-writing initialisation\n",
    "ornn_optim_ng = model.make_nograd(ornn_optim);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAM(1e-4)\n",
    "pars = Flux.params(nn, Zmap);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 300\n",
    "opt.eta = 1e-3 #0.5e-4\n",
    "shuffle_examples = true\n",
    "\n",
    "nB = length(trainIter)\n",
    "W = mocaputil.weights(trainIter; as_pct=false) ./ batch_size\n",
    "\n",
    "history = ones(n_epochs*nB) * NaN\n",
    "\n",
    "for ee in 1:n_epochs\n",
    "    rnn = RNN(size(ornn_optim,3), size(ornn_optim,1), ornn_optim.σ)\n",
    "    \n",
    "    if shuffle_examples\n",
    "        mtl_ixs, trainData = mocaputil.indexed_shuffle(trainIter)\n",
    "    else\n",
    "        mtl_ixs, trainData = 1:length(trainIter), trainIter\n",
    "    end\n",
    "    for (ii, (Yb, Ub, h0)) in zip(mtl_ixs, trainData)\n",
    "        h0 && Flux.reset!(rnn)\n",
    "        Tb = size(Yb, 2)      # not constant\n",
    "        Zs_post = Zmap[:,ii]  #.+ convert(Array{Float32}, AxUtil.Random.sobol_gaussian(m_bprop,2)'*0.01)\n",
    "        \n",
    "        c_ornn = model.make_rnn_psi(ornn_optim, nn(Zs_post), 1f0)\n",
    "        \n",
    "        model.build_rnn!(rnn, c_ornn)\n",
    "        x̂ = reduce(hcat, [rnn(Ub[:,i]) for i in 1:Tb])  |> Tracker.collect\n",
    "        #         ŷ = let m=ornn_optim; m.C*x̂ + m.D*Ub .+ m.d; end   # keep same C, D, d ∀ tasks\n",
    "        ŷ = let m=c_ornn; m.C*x̂ + m.D*Ub .+ m.d; end                 # adapt C, D, d too.\n",
    "        obj = mean(x->x^2, Yb - ŷ) * 8^2 * W[ii]\n",
    "\n",
    "        # Prior penalty\n",
    "        obj += 0.5*sum(Zs_post .* Zs_post)\n",
    "        \n",
    "        Tracker.back!(obj)\n",
    "        history[(ee-1)*nB + ii] = obj.data\n",
    "        \n",
    "        if ii % 34 == 0\n",
    "            for layer in nn.layers\n",
    "                obj += 1e-3*sum(abs, layer.W)\n",
    "                obj += 1e-3*sum(abs, layer.b)\n",
    "            end\n",
    "            \n",
    "            for p in pars\n",
    "                Tracker.update!(opt, p, Tracker.grad(p))\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        rnn.cell.h.data .= 0       # initial state is a param :/. Easier to reset here.\n",
    "        Flux.truncate!(rnn);\n",
    "    end\n",
    "    (ee % 1 == 0) && println(sqrt(mean(history[(1:nB) .+ nB*(ee-1)]))); flush(stdout)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot optimisation progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(sqrt.(DSP.conv(history, Windows.rect(nB))[nB:end-nB+1]/nB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gca()\n",
    "for i in 1:7\n",
    "    ixs = segment_lkp[i]\n",
    "    z = Zmap.data[:, ixs]\n",
    "    ax.scatter(z[1,:], z[2,:], color=ColorMap(\"tab10\")(i-1), alpha=0.5)\n",
    "end\n",
    "legend(style_names[(1:7) .+ 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error(\"safeguard\")\n",
    "BSON.bson(format(\"ornn{:d}_pool_{:d}{:02d}_v{:d}.bson\", \n",
    "        d_state, day(today()), month(today()), batch_size), m=ornn_optim_ng, Zmap=Zmap.data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global optimisation of latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsmp = 300\n",
    "_Zsmp = cholesky(cov(Zmap.data')).U * randn(Float32, 2, nsmp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate error matrix with above samples\n",
    "res = ones(Float32, length(trainIter), nsmp)\n",
    "\n",
    "ornn_optim_ng = model.make_nograd(ornn_optim);\n",
    "rnn_ng = mapleaves(Tracker.data, RNN(d_in, d_state, ornn_optim.σ))\n",
    "@time for i in 1:nsmp\n",
    "    _ψ = nn_ng(_Zsmp[:,i]);\n",
    "    c_ornn = model.make_rnn_psi(ornn_optim_ng, _ψ, 1f0)\n",
    "    model.build_rnn!(rnn_ng, c_ornn)\n",
    "    for (n, (Yb, Ub, h0)) in enumerate(trainIter)\n",
    "        h0 && Flux.reset!(rnn_ng)\n",
    "        Tb = size(Yb, 2)\n",
    "        x̂ = reduce(hcat, [rnn_ng(Ub[:,i]) for i in 1:Tb])\n",
    "        ŷ = let m=c_ornn; m.C*x̂ + m.D*Ub .+ m.d; end\n",
    "        res[n,i] = mean(x->x^2, Yb - ŷ)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find MAP of implicit posterior (SNIS)\n",
    "pz = softmax(-1*(res').^2)   # note that this is much less peaked than it should be=> mean not sum.\n",
    "z_smpopt = copy(Zmap.data)\n",
    "for i in 1:length(trainIter)\n",
    "    z_smpopt[:,i] = _Zsmp[:, argmax(pz[:,i])]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to compare with current position\n",
    "ax = gca()\n",
    "# ax.scatter(_Zsmp[:,1], _Zsmp[:,2], alpha=0.1)\n",
    "for i in 1:7\n",
    "    ixs = segment_lkp[i]\n",
    "    z = z_smpopt[:, ixs] .+ randn(Float32, 2, length(ixs))*0.005\n",
    "    ax.scatter(z[1,:], z[2,:], color=ColorMap(\"tab10\")(i-1), alpha=0.5)\n",
    "end\n",
    "legend(style_names[(1:7) .+ 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update latents\n",
    "error(\"safeguard\")\n",
    "Zmap.data .= z_smpopt .+ randn(Float32, 2, length(trainIter))*0.005;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise fit (and MT variability) for a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_i = 400\n",
    "n_draws = 3\n",
    "\n",
    "trainIters = collect(trainIter);\n",
    "_Yb, _Ub, _h = trainIters[dset_i]\n",
    "_Tb = size(_Yb, 2)\n",
    "_eps = cholesky(cov(Zmap.data')).U * randn(Float32, 2, n_draws)\n",
    "_eps = Zmap.data[:, rand(Categorical(ones(length(trainIter))/length(trainIter)), n_draws)]\n",
    "_eps[:,1] = Zmap.data[:,dset_i]\n",
    "cldsY = map(1:n_draws) do i\n",
    "    _ψ = nn_ng(_eps[:,i]);    \n",
    "    c_ornn = model.make_rnn_psi(ornn_optim_ng, _ψ, 1f0)\n",
    "    model.build_rnn!(rnn_ng, c_ornn)\n",
    "    x̂ = reduce(hcat, [rnn_ng(_Ub[:,i]) for i in 1:_Tb])\n",
    "    let m=c_ornn; m.C*x̂ + m.D*_Ub .+ m.d; end\n",
    "end\n",
    "\n",
    "fig, axs = subplots(5,4,figsize=(10,10))\n",
    "offset = 0\n",
    "for i = 1:20\n",
    "    axs[:][i].plot(_Yb'[:, i+offset])\n",
    "    for j in 1:n_draws\n",
    "        axs[:][i].plot(cldsY[j]'[:, i+offset], alpha=0.4)\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
