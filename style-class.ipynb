{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Revise\n",
    "using LinearAlgebra, Random\n",
    "using StatsBase, Statistics\n",
    "using Distributions, MultivariateStats   # Categorical, P(P)CA\n",
    "using Quaternions    # For manipulating 3D Geometry\n",
    "using MeshCat        # For web visualisation / animation\n",
    "using PyPlot         # Plotting\n",
    "using AxUtil         # Cayley, skew matrices\n",
    "using Flux           # Optimisation\n",
    "using DSP            # convolution / low-pass (MA) filter\n",
    "\n",
    "# small utils libraries\n",
    "using ProgressMeter, Formatting, ArgCheck, Dates\n",
    "using BSON, NPZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_MOCAP_MTDS = \".\" \n",
    "\n",
    "# Data loading and transformation utils\n",
    "include(joinpath(DIR_MOCAP_MTDS, \"io.jl\"))\n",
    "\n",
    "# MeshCat skeleton visualisation tools\n",
    "include(joinpath(DIR_MOCAP_MTDS, \"mocap_viz.jl\"))\n",
    "\n",
    "# Data scaling utils\n",
    "include(joinpath(DIR_MOCAP_MTDS, \"util.jl\"))\n",
    "\n",
    "# Models: LDS\n",
    "include(joinpath(DIR_MOCAP_MTDS, \"models.jl\"))\n",
    "\n",
    "# Table visualisation\n",
    "include(joinpath(DIR_MOCAP_MTDS, \"pretty.jl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "##    CUSTOM WIDELY USED FUNCTIONS\n",
    "function zero_grad!(P) \n",
    "    for x in P\n",
    "        x.grad .= 0\n",
    "    end\n",
    "end\n",
    "\n",
    "const NoGradModels = Union{model.MyLDS_ng, model.ORNN_ng}\n",
    "const _var_cache = IdDict()\n",
    "\n",
    "mse(Δ::AbstractArray, scale=size(Δ, 1)) = mean(x->x^2, Δ)*scale\n",
    "\n",
    "function mse(d::mocaputil.DataIterator, m::NoGradModels)\n",
    "    obj = map(d) do (y, u, new_state)\n",
    "        new_state && (m.h .= zeros(size(m, 1))) \n",
    "        mse(m(u) - y)\n",
    "    end\n",
    "    m.h .= zeros(size(m, 1))\n",
    "    return dot(obj, mocaputil.weights(d, as_pct=true))\n",
    "end\n",
    "\n",
    "\n",
    "mse(Ds::Vector{D}, m::NoGradModels) where {D <: Dict} = mse(mocaputil.DataIterator(Ds, 1000000), m)\n",
    "mse(D::Dict, m::NoGradModels) = mse(m(D[:U]) - D[:Y])\n",
    "mse(V::Tuple, m::NoGradModels) = mse(m(V[2]) - V[1])\n",
    "\n",
    "# Calculate variance\n",
    "function _calc_var!(cache::IdDict, d::mocaputil.DataIterator)\n",
    "    Y = reduce(hcat, [y for (y, u, h) in d])\n",
    "    _var_cache[d] = var(Y, dims=2)\n",
    "end\n",
    "\n",
    "function _calc_var!(cache::IdDict, d::Vector{D}) where {D <: Dict}\n",
    "    Y = reduce(hcat, [dd[:Y] for dd in d])\n",
    "    _var_cache[d] = var(Y, dims=2)\n",
    "end\n",
    "\n",
    "function Statistics.var(d::Union{mocaputil.DataIterator, Vector{D}}) where {D <: Dict}\n",
    "    !haskey(_var_cache, d) && _calc_var!(_var_cache, d)\n",
    "    return _var_cache[d]\n",
    "end\n",
    "Statistics.var(d::Dict) = var(d[:Y], dims=2)\n",
    "\n",
    "# Standardised MSE\n",
    "smse(Δ::AbstractArray, scale=size(Δ, 1)) = mse(Δ, scale) / sum(var(Δ, dims=2))\n",
    "\n",
    "smse(d::mocaputil.DataIterator, m::NoGradModels) = mse(d, m) / sum(var(d))\n",
    "smse(D::Dict, m::NoGradModels) = mse(m(D[:U]) - D[:Y]) / sum(var(D))\n",
    "smse(Ds::Vector{D}, m::NoGradModels) where {D <: Dict} = mse(mocaputil.DataIterator(Ds, 1000000), m) / sum(var(Ds))\n",
    "smse(D::Tuple, m::NoGradModels) = mse(D, m) / sum(var(D[1], dims=2))\n",
    "\n",
    "rsmse(args...) = sqrt(smse(args...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mse(d::mocaputil.DataIterator, m::model.MTLDS_ng, z::AbstractArray)\n",
    "    @argcheck size(z, 2) == length(d)\n",
    "    obj = map(enumerate(d)) do (ii, (y, u, new_state))\n",
    "        new_state && (m.h .= zeros(size(m, 1))) \n",
    "        cmodel = model.make_lds(m, z[:,ii], m.η_h)\n",
    "        mse(cmodel(u) - y)\n",
    "    end\n",
    "    m.h .= zeros(size(m, 1))\n",
    "    return dot(obj, mocaputil.weights(d, as_pct=true))\n",
    "end\n",
    "\n",
    "\n",
    "function mse(d::mocaputil.DataIterator, m::model.ORNN_ng, z::AbstractArray, nn::Chain)\n",
    "    @argcheck size(z, 2) == length(d)\n",
    "    obj = map(enumerate(d)) do (ii, (y, u, new_state))\n",
    "        new_state && (m.h .= zeros(size(m, 1))) \n",
    "        cmodel = model.make_rnn_psi(m, Tracker.data(nn(z[:,ii])), 1f0)\n",
    "        mse(cmodel(u) - y)\n",
    "    end\n",
    "    m.h .= zeros(size(m, 1))\n",
    "    return dot(obj, mocaputil.weights(d, as_pct=true))\n",
    "end\n",
    "\n",
    "smse(d::mocaputil.DataIterator, m::model.MTLDS_ng, z::AbstractArray) = mse(d, m, z) / sum(var(d))\n",
    "smse(d::mocaputil.DataIterator, m::model.ORNN_ng, z::AbstractArray, nn::Chain) = mse(d, m, z, nn) / sum(var(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOGRADMODELS FAILED ON RELOAD\n",
    "mse(Ds::Vector{D}, m::model.ORNN_ng) where {D <: Dict} = mse(mocaputil.DataIterator(Ds, 1000000), m)\n",
    "mse(D::Dict, m::model.ORNN_ng) = mse(m(D[:U]) - D[:Y])\n",
    "mse(V::Tuple, m::model.ORNN_ng) = mse(m(V[2]) - V[1])\n",
    "function mse(d::mocaputil.DataIterator, m::model.ORNN_ng)\n",
    "    obj = map(d) do (y, u, new_state)\n",
    "        new_state && (m.h .= zeros(size(m, 1))) \n",
    "        mse(m(u) - y)\n",
    "    end\n",
    "    m.h .= zeros(size(m, 1))\n",
    "    return dot(obj, mocaputil.weights(d, as_pct=true))\n",
    "end\n",
    "smse(d::mocaputil.DataIterator, m::model.ORNN_ng) = mse(d, m) / sum(var(d))\n",
    "smse(D::Dict, m::model.ORNN_ng) = mse(m(D[:U]) - D[:Y]) / sum(var(D))\n",
    "smse(Ds::Vector{D}, m::model.ORNN_ng) where {D <: Dict} = mse(mocaputil.DataIterator(Ds, 1000000), m) / sum(var(Ds))\n",
    "smse(D::Tuple, m::model.ORNN_ng) = mse(D, m) / sum(var(D[1], dims=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Data\n",
    "See `2_Preprocess.ipynb`\n",
    "\n",
    "**Note that in the current harddisk state**,\n",
    "* `edin_Ys_30fps.bson` was created with `include_ftcontact=false, fps=30`,\n",
    "* `edin_Xs_30fps.bson` was created with `include_ftcontact=true, include_ftmid=true, joint_pos=false, fps=fps, speed=false`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = \"../data/mocap/edin-style-transfer/\"\n",
    "files_edin = [joinpath(database, f) for f in readdir(database)];\n",
    "style_name_edin = [x[1] for x in match.(r\"\\.\\./[a-z\\-]+/[a-z\\-]+/[a-z\\-]+/([a-z]+)_.*\", files_edin)];\n",
    "styles = unique(style_name_edin)\n",
    "styles_lkp = [findall(s .== style_name_edin) for s in styles];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "Usraw = BSON.load(\"edin_Xs_30fps_final.bson\")[:Xs];\n",
    "Ysraw = BSON.load(\"edin_Ys_30fps_final.bson\")[:Ys];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ysraw = [y[2:end,:] for y in Ysraw]\n",
    "# Usraw = [hcat(u[2:end,1:end-8], u[1:end-1,end-7:end]) for u in Usraw];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise inputs and outputs\n",
    "standardize_Y = fit(mocaputil.MyStandardScaler, reduce(vcat, Ysraw),  1)\n",
    "standardize_U = fit(mocaputil.MyStandardScaler, reduce(vcat, Usraw),  1)\n",
    "\n",
    "Ys = [mocaputil.scale_transform(standardize_Y, y[2:end, :] ) for y in Ysraw];  # (1-step ahead of u)\n",
    "Us = [mocaputil.scale_transform(standardize_U, u[1:end-1,:]) for u in Usraw];  # (1-step behind y)\n",
    "\n",
    "@assert (let c=cor(Usraw[1][1:end-1, 4:end], Ysraw[1][2:end, :], dims=1); \n",
    "        !isapprox(maximum(abs.(c[.!isnan.(c)])), 1.0); end) \"some input features perfectly correlated\"\n",
    "\n",
    "# to invert: `mocaputil.invert(standardize_Y, y)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENSE CHECK\n",
    "# check that no bugs in constructing U, Y (i.e. esp that t's align and can predict U --> Y)\n",
    "let c=cor(reduce(vcat, Us) |>f64, reduce(vcat, Ys) |> f64, dims=1)\n",
    "    imshow(c, aspect=\"auto\")\n",
    "    nonan_c = c[.!isnan.(c)]\n",
    "    title(format(\"max (abs) corrcoeff: {:.8f}\", maximum(abs.(nonan_c))))\n",
    "    flush(stdout)\n",
    "#     display(findmax(reshape(nonan_c, size(c, 1) - 2, size(c,2))))\n",
    "#     printfmtln(\"10th best result {:.5f}\", reverse(sort(nonan_c))[10]) \n",
    "end\n",
    "colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_offsets = BSON.load(\"smooth_offsets_per_file.bson\")[:offsets];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "expmtdata = mocapio.ExperimentData(Ysraw, [Matrix(y') for y in Ys], \n",
    "    [Matrix(u') for u in Us], styles_lkp);\n",
    "# see ?mocapio.get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training set for STL and pooled models.\n",
    "style_ix = 1\n",
    "train_ixs = setdiff(1:8, style_ix)\n",
    "min_size = 63;\n",
    "batch_size = 64;\n",
    "\n",
    "trainPool, validPool, testPool = mocapio.get_data(expmtdata, style_ix, :split, :pooled)\n",
    "trainIter = mocaputil.DataIterator(trainPool, 64, min_size=min_size);\n",
    "trainIters = collect(trainIter);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "testIter = mocaputil.DataIterator(testPool, 64, min_size=min_size);\n",
    "testIters = collect(testIter);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_lens = [length(mocaputil.DataIterator(mocapio.get_data(expmtdata, i, :train, :stl, split=[0.875,0.125]),\n",
    "            64, min_size=63)) for i in train_ixs];\n",
    "segment_lkp = [collect(i+1:j) for (i,j) in zip(vcat(0, cumsum(segment_lens[1:end-1])), cumsum(segment_lens))];\n",
    "segment_names = [\"angry\", \"childlike\", \"depressed\", \"neutral\", \"old\", \"proud\", \"sexy\", \"strutting\"][train_ixs];\n",
    "pretty.table(reshape(cumsum(vcat(1, segment_lens)[1:end-1]), :, 1), header_col=segment_names, dp=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unsqueeze(x, d) = reshape(x, (size(x)[1:d-1]..., 1, size(x)[d:end]...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "function data_ahead(dataIters, start_ix, k_ahead)\n",
    "    reduce(hcat, [dataIters[i][1] for i in start_ix+1:start_ix+k_ahead]),\n",
    "    reduce(hcat, [dataIters[i][2] for i in start_ix+1:start_ix+k_ahead])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **** interacting directly with python codebase.\n",
    "# **** In order to keep things simple, we'll just use the filesystem to pass data.\n",
    "using PyCall\n",
    "pysys = pyimport(\"sys\")\n",
    "pytorch = pyimport(\"torch\")\n",
    "pushfirst!(PyVector(pysys.\"path\"), normpath(pwd(), \"../human-motion-prediction-pytorch/src\"));\n",
    "pymt = pyimport(\"forjulia\")   #HACK: most modules in dir have underscores => PyCall.jl doesn't import these :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_args_ = Dict{String, Any}(\"seq_length_out\"=>64, \"decoder_size\"=>1024, \"batch_size\"=>16,\n",
    "            \"latent_k\"=>3,\n",
    "            \"human_size\"=>64, \n",
    "            \"input_size\"=>44,\n",
    "            \"style_ix\"=>style_ix,\n",
    "            \"use_cpu\"=>true, \n",
    "            \"data_dir\"=>\".\");\n",
    "\n",
    "# =========== LEAVE BELOW ALONE => FORMATTING FOR INPUT ARGS AND CMDLINE =================\n",
    "base_args = filter(x->!(x.second isa Bool) || x.second, base_args_)  # remove all \"false\" arguments (implicit)\n",
    "base_args = Dict(k=> (v isa Bool && v == true) ? \"\" : v for (k,v) in base_args)  # replace all \"true\" args\n",
    "base_args = [join([\"--\"*k, v], \" \") for (k,v) in base_args]   # format for cmdline\n",
    "base_args = filter(x->length(x)>0, reduce(vcat, split.(base_args, \" \")));  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!(@isdefined orig_pystdout) && (orig_pystdout = pysys.stdout; pysys.stdout = stdout);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyb = pyimport(\"runbmark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example load pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_ix = 4\n",
    "_mname = [\"open_1_3000\", \"open_2_18000\", \"open_3_3000\", \"open_4_13000\", \n",
    "        \"open_5_6000\", \"open_6_4000\", \"open_7_15000\", \"open_8_6000\"][style_ix]\n",
    "load_args = []\n",
    "push!(load_args, \"--style_ix\")\n",
    "push!(load_args, string(7))\n",
    "push!(load_args, \"--load\")\n",
    "push!(load_args, \"experiments/GRU/\" * _mname)\n",
    "push!(load_args, \"--use_cpu\")\n",
    "load_args = pyb.parseopts4bmark.parse_args(load_args)\n",
    "load_args = pyb.parseopts4bmark.initial_arg_transform(load_args)\n",
    "mtorch_b = pyb.create_model(load_args, [1,2], false)\n",
    "mtorch_b.eval();\n",
    "mtorch_b.num_layers = 1   # HACK: wasn't in first version.\n",
    "mtorch_b.target_seq_len = 196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "function resample_output(Y, U; target_delta=0.03*2π)\n",
    "    d, Yt = size(Y)\n",
    "    Δs = mod2pi.(-diff(atan.(U[end-1, :], U[end, :])))\n",
    "    cur_time = vcat(0, cumsum(Δs))\n",
    "    N = Int(floor(cur_time[end]/target_delta))\n",
    "    reqd_time = cumsum(vcat(0, repeat([target_delta], N)))\n",
    "    c_old = 1\n",
    "    \n",
    "    Yrsmp = ones(eltype(Y), d, N) * NaN\n",
    "    Ursmp = ones(eltype(U), size(U,1), N) * NaN\n",
    "    for t in 1:N\n",
    "        tt = reqd_time[t]\n",
    "        while tt > cur_time[c_old+1]\n",
    "            c_old += 1\n",
    "        end\n",
    "        if tt == 0 && c_old == 1\n",
    "            Yrsmp[:, t] = Y[:, c_old]\n",
    "            Ursmp[:, t] = U[:, c_old]\n",
    "            continue\n",
    "        end\n",
    "        pct = (tt - cur_time[c_old])/(cur_time[c_old+1] - cur_time[c_old])\n",
    "        Yrsmp[:, t] = Y[:, c_old]*(1-pct) + Y[:, c_old+1]*pct\n",
    "        Ursmp[:, t] = U[:, c_old]*(1-pct) + U[:, c_old+1]*pct\n",
    "    end\n",
    "    return Yrsmp, Ursmp\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "length(mocaputil.DataIterator(mocapio.get_data(expmtdata, 1, :train, :stl, split=[0.8,0.0,0.2]),\n",
    "    64, min_size=min_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "length(trainIters[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainIters = []\n",
    "validIters = []\n",
    "for style in 1:8\n",
    "    trainPoolstyle = mocapio.get_data(expmtdata, style, :train, :stl, split=[0.8,0.0,0.2])\n",
    "    validPoolstyle = mocapio.get_data(expmtdata, style, :test, :stl, split=[0.8,0.0,0.2])\n",
    "    for x in trainPoolstyle\n",
    "        x[:Y], x[:U] = resample_output(x[:Y], x[:U])\n",
    "    end\n",
    "    for x in validPoolstyle\n",
    "        x[:Y], x[:U] = resample_output(x[:Y], x[:U])\n",
    "    end\n",
    "    trainIter = mocaputil.DataIterator(trainPoolstyle, 64, min_size=min_size);\n",
    "    validIter = mocaputil.DataIterator(validPoolstyle, 64, min_size=min_size);\n",
    "    push!(trainIters, collect(trainIter))\n",
    "    push!(validIters, collect(validIter))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "for style in 1:8\n",
    "    trainIters[style] = filter(x->size(x[1], 2) == 64, trainIters[style])\n",
    "    validIters[style] = filter(x->size(x[1], 2) == 64, validIters[style])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru = GRU(67, 512)\n",
    "fc1 = Chain(Dense(512, 300, relu), Dense(300, 8, identity))\n",
    "gru.init.data .= 0\n",
    "\n",
    "function _forwardlogit(Y::AbstractArray, gru, fc1)\n",
    "    for t in 1:size(Y, 2)\n",
    "        gru(Y[:,t,:])\n",
    "    end\n",
    "    return fc1(gru.state)\n",
    "end\n",
    "\n",
    "function forward(Y::AbstractArray, gru, fc1)\n",
    "    logittarget_hat = _forwardlogit(Y, gru, fc1)\n",
    "    return softmax(logittarget_hat)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAM(1e-4)\n",
    "ps = Flux.params(gru, fc1)\n",
    "history = zeros(400, 2) * NaN\n",
    "\n",
    "test_gru, test_fc1 = map(x->Flux.mapleaves(Tracker.data, x), (gru, fc1))\n",
    "\n",
    "for i in 1:400\n",
    "    Flux.reset!(gru)\n",
    "    \n",
    "    cY = map(1:8) do style\n",
    "        unsqueeze(trainIters[style][rand(1:length(trainIters[style]))][1], 3)\n",
    "    end |> x -> cat(x..., dims=3);\n",
    "    \n",
    "    target = Flux.onehotbatch(1:8, 1:8)\n",
    "    logittarget_hat = _forwardlogit(cY, gru, fc1)\n",
    "    loss = Flux.logitcrossentropy(logittarget_hat, target)\n",
    "    \n",
    "    Tracker.back!(loss)\n",
    "    for p in ps\n",
    "        Flux.Tracker.update!(opt, p, p.grad)\n",
    "    end\n",
    "    \n",
    "    # Validation\n",
    "    Flux.reset!(test_gru)\n",
    "    validY = map(1:8) do style\n",
    "        unsqueeze(validIters[style][rand(1:length(validIters[style]))][1], 3)\n",
    "    end |> x -> cat(x..., dims=3);\n",
    "    valid_logittarget_hat = _forwardlogit(validY, test_gru, test_fc1)\n",
    "    valid_loss = Flux.logitcrossentropy(valid_logittarget_hat, target)\n",
    "    \n",
    "    if i % 5 == 0\n",
    "        println(format(\"Loss at {:03d} is {:01.4f} ({:01.4f})\", i, loss.data, valid_loss.data))\n",
    "    end\n",
    "    history[i, 1] = loss.data\n",
    "    history[i, 2] = valid_loss.data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.crossentropy(_pred', Flux.onehot(3, 1:8)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Flux.reset!(gru)\n",
    "forward(trainIters[4][72][1], gru, fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "_mce, _pred = forward(trainIters[3][72][1], Flux.onehot(3, 1:8), gru, fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "1. Verify optimisation is working.\n",
    "2. Hold out validation set for training.\n",
    "3. Experiment on style transfer data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# style_ix = 4\n",
    "# _mname = [\"open_1_3000\", \"open_2_18000\", \"open_3_3000\", \"open_4_13000\", \n",
    "#         \"open_5_6000\", \"open_6_4000\", \"open_7_15000\", \"open_8_6000\"][style_ix]\n",
    "# load_args = []\n",
    "# push!(load_args, \"--style_ix\")\n",
    "# push!(load_args, string(7))\n",
    "# push!(load_args, \"--load\")\n",
    "# push!(load_args, \"experiments/GRU/\" * _mname)\n",
    "# push!(load_args, \"--use_cpu\")\n",
    "# load_args = pyb.parseopts4bmark.parse_args(load_args)\n",
    "# load_args = pyb.parseopts4bmark.initial_arg_transform(load_args)\n",
    "# mtorch_b = pyb.create_model(load_args, [1,2], false)\n",
    "# mtorch_b.eval();\n",
    "# mtorch_b.num_layers = 1   # HACK: wasn't in first version.\n",
    "# mtorch_b.target_seq_len = 196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_args = copy(base_args)\n",
    "push!(load_args, \"--load\")\n",
    "# push!(load_args, \"experiments/bottleneck_16_1_lowlr_10000\")\n",
    "# push!(load_args, \"experiments/dynamicsdict_256_20000\")\n",
    "# push!(load_args, \"--dynamicsdict\")\n",
    "# push!(load_args, \"experiments/final/k3_bottleneck24_2_prec9_mtrnn_lowlr20000\")\n",
    "# push!(load_args, format(\"experiments/final/k3_bottleneck24_{:d}_prec9_mtrnn_lowlr20000\", style_ix))\n",
    "# push!(load_args, format(\"experiments/biasonly/style{:d}_128_8e-4_k3_20000\", style_ix))\n",
    "push!(load_args, format(\"experiments/biasonly/style9_128_12e-4_k8_40000\", style_ix))  # <= ***\n",
    "# push!(load_args, format(\"experiments/nobias/style9_k8_30000\")) # <= ***\n",
    "# push!(load_args, format(\"experiments/final/k3_bottleneck24_{:d}_mtrnn_lowlr20000\", style_ix))\n",
    "# push!(load_args, \"experiments/final/2d_embedding_model20000\")\n",
    "# push!(load_args, \"experiments/final/k3_bottleneck16_1_mtrnn_lowlr20000\")\n",
    "load_args = pymt.parseopts.parse_args(load_args)\n",
    "load_args = pymt.parseopts.initial_arg_transform(load_args)\n",
    "mtorch = pymt.learn_mtfixbmodel.create_model(load_args, 850)\n",
    "mtorch.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "allPools = mocaputil.DataIterator(mocapio.get_data(expmtdata, style_ix, :all, :pooled), 64, \n",
    "    min_size=min_size) |> collect;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk64(x) = [x[(1:64) .+ (i-1)*64] for i in 1:(length(x)÷64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BSON.bson(\"exemplar_ixs.bson\", ixs=[[1,55,72,88], [115,147,204,230], [247,269,287,318], [359,376,411,431], \n",
    "#         [487,503,540,573],[601,617,644,661], [691,716,778,823], [848,867,889,930]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplar_ixs = BSON.load(\"exemplar_ixs.bson\")[:ixs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "ixs_by_style = [i:j for (i,j) in zip(cumsum(vcat(1, ls[1:end-1])), cumsum(ls))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = [114, 132, 112, 128, 114, 90, 157, 117];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = [length(filter(x->size(x[1], 2) == 64, collect(mocaputil.DataIterator(mocapio.get_data(expmtdata, style, \n",
    "                        :all, :stl), 64, min_size=63)))) for style in 1:8]\n",
    "ls = [length(collect(mocaputil.DataIterator(mocapio.get_data(expmtdata, style, \n",
    "                        :all, :stl), 64, min_size=63))) for style in 1:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "[rand(i:j) for (i,j) in zip(cumsum(vcat(1, ls[1:end-1])), cumsum(ls))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainItersOrig = mocaputil.DataIterator(mocapio.get_data(expmtdata, 1, :all, :pooled), \n",
    "    64, min_size=min_size) |> collect;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 .+ vcat(0, ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zsn = []\n",
    "scores = []\n",
    "@showprogress for n = 1:20\n",
    "    yhats = []\n",
    "    score = []\n",
    "    _Zixs = [rand(i:j-1) for (i,j) in zip(cumsum(vcat(1, ls[1:end-1])), cumsum(ls))] \n",
    "    for style_ix = 1:8\n",
    "    #     _Zixs = [20, 188, 312, 424, 553, 670, 733, 880]\n",
    "        for _batch_num in [3 + cumsum(vcat(0, ls))[style_ix]]   #exemplar_ixs[style_ix]\n",
    "            _Yb, _Ub = trainItersOrig[_batch_num]\n",
    "            yhat = []\n",
    "            \n",
    "            @pywith pytorch.no_grad() begin\n",
    "                for j in 1:1\n",
    "                    μprop = get(mtorch.mt_net.Z_mu, _Zixs[j] -1)\n",
    "                    out = mtorch.forward(pytorch.tensor(reshape(_Ub', 1, :, 35)), \n",
    "                            pytorch.tensor(μprop), \n",
    "                            pytorch.tensor(repeat([1f-6],1,8)))[1].numpy()[1,:,:]\n",
    "                    yhat_rsmp, _ = resample_output(out', _Ub)\n",
    "                    push!(yhat, yhat_rsmp)\n",
    "                end\n",
    "            end\n",
    "            push!(yhats, yhat)\n",
    "            \n",
    "            out = zeros(8,8)*NaN\n",
    "            for j in 1:1\n",
    "                Flux.reset!(test_gru)\n",
    "#                 display(yhat[j])\n",
    "                out[:,1] = forward(yhat[j], test_gru, test_fc1)[:]\n",
    "            end\n",
    "            push!(score, diag(out))\n",
    "        end\n",
    "    end\n",
    "    push!(scores, mean(score))\n",
    "    push!(Zsn, _Zixs)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zsn[argmax(reduce(hcat, scores)[1,:])][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "_Zs_mtbias2 = [reduce(hcat, Zsn)'[j, i] for (i, j) in \n",
    "        enumerate(mapslices(argmax, reduce(hcat, scores)', dims=1)[:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "join(map(string, _Zs_mtbias2), \", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mapslices(argmax, reduce(hcat, scores)', dims=1)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _Zs_bias_only = [75, 209, 274, 408, 535, 619, 798, 947];\n",
    "_Zs_bias_only = [94, 182, 288, 475, 568, 617, 794, 851];\n",
    "_Zs_bias_only = [10, 186, 282, 376, 517, 675, 822, 876];\n",
    "_Zs_bias_only_avg4 = [11, 186, 335, 425, 590, 617, 763, 963]\n",
    "_Zs_mtbias = [50, 119, 293, 427, 554, 668, 825, 856];\n",
    "# _Zs_mtbias = [64, 188, 248, 479, 555, 618, 746, 857];\n",
    "# _Zs_mtbias = [5, 189, 322, 445, 525, 649, 701, 857];\n",
    "_Zs_mtbias_avg4 = [48, 118, 341, 405, 553, 684, 762, 855];\n",
    "_Zs_orig = [20, 188, 312, 424, 553, 670, 733, 880];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = []\n",
    "_Zixs = _Zs_bias_only_avg4\n",
    "avg4 = true   # true\n",
    "@showprogress for style_ix = 1:8\n",
    "    outs_batch = []\n",
    "    batches = avg4 ? exemplar_ixs[style_ix] : [3 + cumsum(vcat(0, ls))[style_ix]]\n",
    "    for _batch_num in batches\n",
    "\n",
    "        _Yb, _Ub = trainItersOrig[_batch_num]\n",
    "        yhat = []\n",
    "        @pywith pytorch.no_grad() begin\n",
    "            for j in 1:8\n",
    "                μprop = get(mtorch.mt_net.Z_mu, _Zixs[j] -1)\n",
    "                out = mtorch.forward(pytorch.tensor(reshape(_Ub', 1, :, 35)), \n",
    "                        pytorch.tensor(μprop), \n",
    "                        pytorch.tensor(repeat([1f-6],1,8)))[1].numpy()[1,:,:]\n",
    "                yhat_rsmp, _ = resample_output(out', _Ub)\n",
    "                push!(yhat, yhat_rsmp)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        out = zeros(8,8)*NaN\n",
    "        for j in 1:8\n",
    "            Flux.reset!(test_gru)\n",
    "            out[:,j] = forward(yhat[j], test_gru, test_fc1)[:]\n",
    "        end\n",
    "        push!(outs_batch, out)\n",
    "    end\n",
    "    push!(outs, outs_batch)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axs = subplots(2,4, figsize=(10,5))\n",
    "\n",
    "for style_ix = 1:8\n",
    "    out = mean(outs[style_ix])  # mean over the 4 batches\n",
    "    axs[:][style_ix].imshow(out); #colorbar(axs[:][style_ix])\n",
    "    axs[:][style_ix].set_title(style_ix)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "styles = [\"angry\", \"child\", \"depr.\", \"neut.\", \"old\", \"proud\", \"sexy\", \"strut.\"];\n",
    "twodp(x) = format(\"{:.2f}\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gca()\n",
    "\n",
    "diag_color = ColorMap(\"Reds\")(0.3)\n",
    "cmap = ColorMap(\"Greys_r\")\n",
    "\n",
    "_payload = reduce(hcat, [diag(mean(outs[style_ix])) for style_ix in 1:8])\n",
    "_payload = cmap(_payload)\n",
    "diagixs = diagind(_payload[:,:,1])\n",
    "_payload[diagixs] .= diag_color[1]\n",
    "_payload[diagixs .+ 64] .= diag_color[2]\n",
    "_payload[diagixs .+ 128] .= diag_color[3]\n",
    "\n",
    "_im = ax.imshow(reverse(_payload, dims=1))\n",
    "\n",
    "plt.setp(ax, yticks=0:7, yticklabels=reverse(styles))\n",
    "plt.setp(ax, xticks=0:7, xticklabels=styles)\n",
    "\n",
    "ax.set_xlabel(\"source\")\n",
    "ax.set_ylabel(\"target\")\n",
    "# plt.colorbar(_im,fraction=0.022, pad=0.04)\n",
    "\n",
    "for style_ix in 1:8, j in 1:8\n",
    "    val = mean(outs[style_ix])[j, j]\n",
    "    ax.text(style_ix-1, 8-j, twodp(val), ha=\"center\", va=\"center\", \n",
    "        color=ColorMap(\"Greens\")(σ(20*(val-0.5) +1)), fontsize=9)\n",
    "end\n",
    "# savefig(\"img/pub/style_tfer_matrix_avg4.pdf\")\n",
    "# savefig(\"img/pub/style_tfer_matrix_biasonly_avg4.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gca()\n",
    "\n",
    "_im = ax.imshow(reduce(hcat, [diag(mean(outs[style_ix])) for style_ix in 1:8]), cmap=ColorMap(\"Greys_r\"))\n",
    "# ax.set_xticklabels(0:8)\n",
    "# ax.set_yticklabels(0:8)\n",
    "\n",
    "plt.setp(ax, yticks=0:7, yticklabels=styles)\n",
    "plt.setp(ax, xticks=0:7, xticklabels=styles)\n",
    "\n",
    "ax.set_xlabel(\"target\")\n",
    "ax.set_ylabel(\"source\")\n",
    "# plt.colorbar(_im,fraction=0.022, pad=0.04)\n",
    "\n",
    "for style_ix in 1:8, j in 1:8\n",
    "    val = mean(outs[style_ix])[j, j]\n",
    "    ax.text(style_ix-1, j-1, twodp(val), ha=\"center\", va=\"center\", \n",
    "        color=ColorMap(\"Greens\")(σ(20*(val-0.5) -0.4)), fontsize=9)\n",
    "end\n",
    "# savefig(\"img/pub/style_tfer_matrix.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "round.([mean(outs[i]) for i in 1:8][8], digits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gca()\n",
    "_im = ax.imshow(reverse(mean(cat([mean(outs[i]) for i in 1:8]..., dims=3), dims=3)[:,:,1], dims=1), \n",
    "    cmap=ColorMap(\"Greys_r\"))\n",
    "\n",
    "plt.setp(ax, yticks=0:7, yticklabels=reverse(styles))\n",
    "plt.setp(ax, xticks=0:7, xticklabels=styles)\n",
    "\n",
    "ax.set_xlabel(\"target\")\n",
    "ax.set_ylabel(\"predicted\")\n",
    "# plt.colorbar(_im,fraction=0.022, pad=0.04)\n",
    "\n",
    "for i in 1:8, j in 1:8\n",
    "    val = mean([mean(outs[style_ix])[j, i] for style_ix in 1:8])\n",
    "    ax.text(i-1, 8-j, twodp(val), ha=\"center\", va=\"center\", \n",
    "        color=ColorMap(\"Greens\")(σ(20*(val-0.5) +1)), fontsize=9)\n",
    "end\n",
    "# savefig(\"img/pub/style_tfer_avg_confusion_biasonly_avg4.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gca()\n",
    "_im = ax.imshow(reduce(hcat, [diag(outs[style_ix]) for style_ix in 1:8]), cmap=ColorMap(\"Greys_r\"))\n",
    "# ax.set_xticklabels(0:8)\n",
    "# ax.set_yticklabels(0:8)\n",
    "\n",
    "plt.setp(ax, yticks=0:7, yticklabels=styles)\n",
    "plt.setp(ax, xticks=0:7, xticklabels=styles)\n",
    "\n",
    "ax.set_xlabel(\"target\")\n",
    "ax.set_ylabel(\"source\")\n",
    "# plt.colorbar(_im,fraction=0.022, pad=0.04)\n",
    "\n",
    "for style_ix in 1:8, j in 1:8\n",
    "    val = outs[style_ix][j, j]\n",
    "    ax.text(style_ix-1, j-1, twodp(val), ha=\"center\", va=\"center\", \n",
    "        color=ColorMap(\"Greens\")(σ(20*(val-0.5) +1)), fontsize=6)\n",
    "end\n",
    "savefig(\"img/pub/style_tfer_matrix_biasonly.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gca()\n",
    "_im = ax.imshow(reduce(hcat, [diag(outs[style_ix]) for style_ix in 1:8]), cmap=ColorMap(\"Greys_r\"))\n",
    "# ax.set_xticklabels(0:8)\n",
    "# ax.set_yticklabels(0:8)\n",
    "\n",
    "plt.setp(ax, yticks=0:7, yticklabels=styles)\n",
    "plt.setp(ax, xticks=0:7, xticklabels=styles)\n",
    "\n",
    "ax.set_xlabel(\"target\")\n",
    "ax.set_ylabel(\"source\")\n",
    "# plt.colorbar(_im,fraction=0.022, pad=0.04)\n",
    "\n",
    "for style_ix in 1:8, j in 1:8\n",
    "    val = outs[style_ix][j, j]\n",
    "    ax.text(style_ix-1, j-1, twodp(val), ha=\"center\", va=\"center\", \n",
    "        color=ColorMap(\"Greens\")(σ(20*(val-0.5) +1)), fontsize=6)\n",
    "end\n",
    "savefig(\"img/pub/style_tfer_matrix_biasonly2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = gca()\n",
    "_im = ax.imshow(mean(cat([mean(outs[i]) for i in 1:8]..., dims=3), dims=3)[:,:,1], \n",
    "    cmap=ColorMap(\"Greys_r\"))\n",
    "\n",
    "plt.setp(ax, yticks=0:7, yticklabels=styles)\n",
    "plt.setp(ax, xticks=0:7, xticklabels=styles)\n",
    "\n",
    "ax.set_xlabel(\"target\")\n",
    "ax.set_ylabel(\"predicted\")\n",
    "# plt.colorbar(_im,fraction=0.022, pad=0.04)\n",
    "\n",
    "for i in 1:8, j in 1:8\n",
    "    val = mean([mean(outs[style_ix])[j, i] for style_ix in 1:8])\n",
    "    ax.text(i-1, j-1, twodp(val), ha=\"center\", va=\"center\", \n",
    "        color=ColorMap(\"Greens\")(σ(20*(val-0.5) +1)), fontsize=9)\n",
    "end\n",
    "savefig(\"img/pub/style_tfer_avg_confusion_biasonly2_avg4.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
